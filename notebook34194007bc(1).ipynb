{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install tensorflow nightly","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import TensorBoard\nimport tensorflow as tf\n\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-07-02T14:48:30.209036Z","iopub.execute_input":"2021-07-02T14:48:30.209391Z","iopub.status.idle":"2021-07-02T14:48:30.213974Z","shell.execute_reply.started":"2021-07-02T14:48:30.209359Z","shell.execute_reply":"2021-07-02T14:48:30.212958Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# hyper-parameters\nbatch_size = 64\n# 10 categories of images (CIFAR-10)\nnum_classes = 10\n# number of training epochs\nepochs = 30","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:47:02.654244Z","iopub.execute_input":"2021-07-02T11:47:02.654684Z","iopub.status.idle":"2021-07-02T11:47:02.660098Z","shell.execute_reply.started":"2021-07-02T11:47:02.654636Z","shell.execute_reply":"2021-07-02T11:47:02.658701Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# load images from the train  folder\n# def load_images():\n    \n#     def preprocess_image(image,lable):\n                   \n#         # convert [0, 255] range integers to [0, 1] range floats\n#         image = tf.image.convert_image_dtype(image, tf.float32)\n#         return image,lable\n#     # loading the CIFAR-10 dataset, splitted between train and test sets\n#     ds_train, info = tfds.load(\"../input/brest-cancer/Breast Cancer DataSet/Train/\", with_info=True, split=\"train\", as_supervised=True)\n#     ds_test = tfds.load(\"../input/brest-cancer/Breast Cancer DataSet/Test/\", split=\"test\", as_supervised=True)\n#     # repeat dataset forever, shuffle, preprocess, split by batch\n#     ds_train = ds_train.repeat().shuffle(1024).map(preprocess_image).batch(batch_size)\n#     ds_test = ds_test.repeat().shuffle(1024).map(preprocess_image).batch(batch_size)\n#     return ds_train, ds_test, info\n\nfrom os import listdir\nfrom PIL import Image as PImage\nimport PIL\nimport PIL.Image\nfrom tensorflow import keras\nimport pathlib\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-07-02T14:48:23.091739Z","iopub.execute_input":"2021-07-02T14:48:23.092113Z","iopub.status.idle":"2021-07-02T14:48:28.005431Z","shell.execute_reply.started":"2021-07-02T14:48:23.092032Z","shell.execute_reply":"2021-07-02T14:48:28.004502Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# THIS DATA  IS AVAILABLE ON KAGGLE\nbase = \"../input/brest-cancer/Breast Cancer DataSet/\"\ntrain_base=\"Train/\"\ntest_base=\"Test/\"\ndata_dir = pathlib.Path('../input/brest-cancer/Breast Cancer DataSet/Train/')\ntest_data_dir = pathlib.Path('../input/brest-cancer/Breast Cancer DataSet/valid/')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T14:49:22.924996Z","iopub.execute_input":"2021-07-02T14:49:22.925353Z","iopub.status.idle":"2021-07-02T14:49:22.929942Z","shell.execute_reply.started":"2021-07-02T14:49:22.925317Z","shell.execute_reply":"2021-07-02T14:49:22.928790Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = keras.Input(shape=(784,), name=\"digits\")\nx = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\nx = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\noutputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# THIS DATA  IS AVAILABLE ON KAGGLE\nbase = \"../input/brest-cancer/Breast Cancer DataSet/\"\ntrain_base=\"Train/\"\ntest_base=\"Test/\"\ndata_dir = pathlib.Path('../input/brest-cancer/Breast Cancer DataSet/Train/')\ntest_data_dir = pathlib.Path('../input/brest-cancer/Breast Cancer DataSet/valid/')\n\n\ndef run_model():\n    batch_size = 32\n    img_height = 180\n    img_width = 180\n\n\n    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n      data_dir,\n      validation_split=0.2,\n      subset=\"training\",\n      seed=123,\n      image_size=(img_height, img_width),\n      batch_size=batch_size)\n\n    test_data = tf.keras.preprocessing.image_dataset_from_directory(\n      test_data_dir,\n      validation_split=0.2,\n      subset=\"validation\",\n      seed=123,\n      image_size=(img_height, img_width),\n      batch_size=batch_size)\n\n    class_names = train_ds.class_names\n    print(class_names)\n    \n    \n        plt.figure(figsize=(10, 10))\n        for images, labels in test_data.take(1):\n            \n            for i in range(9):\n                \n                ax = plt.subplot(3, 3, i + 1)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(class_names[labels[i]])\n                plt.axis(\"off\")\n                \n    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n\n\n\n    AUTOTUNE = tf.data.AUTOTUNE\n\n    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n    test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(10)\n    ])\n\n    inputs = keras.Input(shape=(784,), name=\"digits\")\n    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    num_classes = 2\n\n    model = tf.keras.Sequential([\n      tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(128, activation='relu'),\n      tf.keras.layers.Dense(num_classes)\n    ])\n    model.compile(\n      optimizer='adam',\n      loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n      metrics=['accuracy'])\n    model.fit(\n      train_ds,\n      validation_data=test_data,\n      epochs=30\n    )\n    \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:06:07.926450Z","iopub.execute_input":"2021-07-02T12:06:07.926913Z","iopub.status.idle":"2021-07-02T12:06:07.945143Z","shell.execute_reply.started":"2021-07-02T12:06:07.926871Z","shell.execute_reply":"2021-07-02T12:06:07.943943Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n\nclass_names = train_ds.class_names\nimage_path=\"../input/brest-cancer/Breast Cancer DataSet/Test/Malignant/SOB_M_DC-14-12312-400-019.png\"\nimg = keras.preprocessing.image.load_img(\n    image_path, target_size=(img_height, img_width)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\n    \n\nmodel=run_model()\npredictions= model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:06:17.638480Z","iopub.execute_input":"2021-07-02T12:06:17.638944Z","iopub.status.idle":"2021-07-02T12:13:11.248849Z","shell.execute_reply.started":"2021-07-02T12:06:17.638909Z","shell.execute_reply":"2021-07-02T12:13:11.247921Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Found 808 files belonging to 2 classes.\nUsing 647 files for training.\nFound 189 files belonging to 2 classes.\nUsing 37 files for validation.\n['Benign', 'Malignant']\nEpoch 1/30\n21/21 [==============================] - 21s 779ms/step - loss: 1.0158 - accuracy: 0.5454 - val_loss: 0.5593 - val_accuracy: 0.5676\nEpoch 2/30\n21/21 [==============================] - 13s 635ms/step - loss: 0.6274 - accuracy: 0.6570 - val_loss: 0.3217 - val_accuracy: 0.9459\nEpoch 3/30\n21/21 [==============================] - 13s 636ms/step - loss: 0.5527 - accuracy: 0.7543 - val_loss: 0.2439 - val_accuracy: 0.9459\nEpoch 4/30\n21/21 [==============================] - 14s 655ms/step - loss: 0.4764 - accuracy: 0.7916 - val_loss: 0.2284 - val_accuracy: 0.9459\nEpoch 5/30\n21/21 [==============================] - 13s 638ms/step - loss: 0.4756 - accuracy: 0.7719 - val_loss: 0.2465 - val_accuracy: 0.9459\nEpoch 6/30\n21/21 [==============================] - 14s 646ms/step - loss: 0.4276 - accuracy: 0.8185 - val_loss: 0.2531 - val_accuracy: 0.9189\nEpoch 7/30\n21/21 [==============================] - 13s 634ms/step - loss: 0.4167 - accuracy: 0.8220 - val_loss: 0.3090 - val_accuracy: 0.9189\nEpoch 8/30\n21/21 [==============================] - 14s 650ms/step - loss: 0.3995 - accuracy: 0.8315 - val_loss: 0.3719 - val_accuracy: 0.8378\nEpoch 9/30\n21/21 [==============================] - 13s 636ms/step - loss: 0.3966 - accuracy: 0.8266 - val_loss: 0.3985 - val_accuracy: 0.8108\nEpoch 10/30\n21/21 [==============================] - 13s 638ms/step - loss: 0.3660 - accuracy: 0.8349 - val_loss: 0.4544 - val_accuracy: 0.8108\nEpoch 11/30\n21/21 [==============================] - 14s 650ms/step - loss: 0.3566 - accuracy: 0.8369 - val_loss: 0.3591 - val_accuracy: 0.8378\nEpoch 12/30\n21/21 [==============================] - 14s 645ms/step - loss: 0.3160 - accuracy: 0.8518 - val_loss: 0.3338 - val_accuracy: 0.8649\nEpoch 13/30\n21/21 [==============================] - 14s 655ms/step - loss: 0.2940 - accuracy: 0.8658 - val_loss: 0.6025 - val_accuracy: 0.7297\nEpoch 14/30\n21/21 [==============================] - 13s 636ms/step - loss: 0.3308 - accuracy: 0.8666 - val_loss: 0.3833 - val_accuracy: 0.8649\nEpoch 15/30\n21/21 [==============================] - 14s 647ms/step - loss: 0.2461 - accuracy: 0.8868 - val_loss: 0.5263 - val_accuracy: 0.7838\nEpoch 16/30\n21/21 [==============================] - 13s 640ms/step - loss: 0.2169 - accuracy: 0.9087 - val_loss: 0.4186 - val_accuracy: 0.8378\nEpoch 17/30\n21/21 [==============================] - 13s 643ms/step - loss: 0.1548 - accuracy: 0.9453 - val_loss: 0.5428 - val_accuracy: 0.7838\nEpoch 18/30\n21/21 [==============================] - 14s 659ms/step - loss: 0.1313 - accuracy: 0.9517 - val_loss: 0.3583 - val_accuracy: 0.8108\nEpoch 19/30\n21/21 [==============================] - 13s 633ms/step - loss: 0.1313 - accuracy: 0.9509 - val_loss: 0.3748 - val_accuracy: 0.8649\nEpoch 20/30\n21/21 [==============================] - 14s 648ms/step - loss: 0.1214 - accuracy: 0.9452 - val_loss: 0.5493 - val_accuracy: 0.8649\nEpoch 21/30\n21/21 [==============================] - 13s 636ms/step - loss: 0.0879 - accuracy: 0.9579 - val_loss: 0.4908 - val_accuracy: 0.8378\nEpoch 22/30\n21/21 [==============================] - 13s 633ms/step - loss: 0.0443 - accuracy: 0.9924 - val_loss: 0.8500 - val_accuracy: 0.8108\nEpoch 23/30\n21/21 [==============================] - 14s 650ms/step - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.5053 - val_accuracy: 0.8919\nEpoch 24/30\n21/21 [==============================] - 13s 633ms/step - loss: 0.0296 - accuracy: 0.9994 - val_loss: 0.6019 - val_accuracy: 0.8108\nEpoch 25/30\n21/21 [==============================] - 14s 650ms/step - loss: 0.0388 - accuracy: 0.9925 - val_loss: 1.7118 - val_accuracy: 0.5946\nEpoch 26/30\n21/21 [==============================] - 13s 637ms/step - loss: 0.2840 - accuracy: 0.8945 - val_loss: 0.9456 - val_accuracy: 0.6486\nEpoch 27/30\n21/21 [==============================] - 13s 631ms/step - loss: 0.1092 - accuracy: 0.9615 - val_loss: 0.2910 - val_accuracy: 0.9459\nEpoch 28/30\n21/21 [==============================] - 14s 646ms/step - loss: 0.0490 - accuracy: 0.9864 - val_loss: 0.4046 - val_accuracy: 0.9189\nEpoch 29/30\n21/21 [==============================] - 13s 633ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.5316 - val_accuracy: 0.8649\nEpoch 30/30\n21/21 [==============================] - 14s 652ms/step - loss: 0.0475 - accuracy: 0.9892 - val_loss: 0.3845 - val_accuracy: 0.9189\n","output_type":"stream"}]},{"cell_type":"code","source":"class_names = [\"Bening\",\"Malignant\"]\nimage_path=\"../input/brest-cancer/Breast Cancer DataSet/Test/Malignant/SOB_M_DC-14-12312-400-019.png\"\nimg = keras.preprocessing.image.load_img(\n    image_path, target_size=(180, 180)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T13:11:37.383963Z","iopub.execute_input":"2021-07-02T13:11:37.384387Z","iopub.status.idle":"2021-07-02T13:11:37.415706Z","shell.execute_reply.started":"2021-07-02T13:11:37.384355Z","shell.execute_reply":"2021-07-02T13:11:37.414461Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"result=\"\"\"This Breast has {} conditions with an {:.2f} percent confidence.\n=Note Benign is not cancers cell while malignant is cancer cell\n\"\"\".format(class_names[np.argmax(score)], 100 * np.max(score))\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T13:11:42.137814Z","iopub.execute_input":"2021-07-02T13:11:42.138249Z","iopub.status.idle":"2021-07-02T13:11:42.170768Z","shell.execute_reply.started":"2021-07-02T13:11:42.138213Z","shell.execute_reply":"2021-07-02T13:11:42.168394Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9dad1341e3fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m result=\"\"\"This Breast has {} conditions with an {:.2f} percent confidence.\n\u001b[1;32m      2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mNote\u001b[0m \u001b[0mBenign\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcancers\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mmalignant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcancer\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \"\"\".format(class_names[np.argmax(score)], 100 * np.max(score))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"],"ename":"NameError","evalue":"name 'score' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model\")\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:14:45.599635Z","iopub.execute_input":"2021-07-02T12:14:45.600410Z","iopub.status.idle":"2021-07-02T12:14:47.377725Z","shell.execute_reply.started":"2021-07-02T12:14:45.600363Z","shell.execute_reply":"2021-07-02T12:14:47.376575Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"reconstructed_model = keras.models.load_model(\"../input/breast-cancer-saved-model/model\")\n\n# Let's check:\n\n\nsavedmodel=reconstructed_model.predict(img_array)\n\n\nscore = tf.nn.softmax(savedmodel[0])\nresult2=\"\"\"This Breast has {} conditions with an {:.2f} percent confidence.\n=Note Benign is not cancers cell while malignant is cancer cell\n\"\"\".format(class_names[np.argmax(score)], 100 * np.max(score))\n\nprint(result2)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T13:12:42.530169Z","iopub.execute_input":"2021-07-02T13:12:42.530555Z","iopub.status.idle":"2021-07-02T13:12:43.407851Z","shell.execute_reply.started":"2021-07-02T13:12:42.530523Z","shell.execute_reply":"2021-07-02T13:12:43.406384Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"This Breast has Malignant conditions with an 99.98 percent confidence.\n=Note Benign is not cancers cell while malignant is cancer cell\n\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path=\"../input/brest-cancer/Breast Cancer DataSet/Test/Malignant/SOB_M_DC-14-12312-400-019.png\"\nimg = keras.preprocessing.image.load_img(\n    image_path, target_size=(img_height, img_width)\n)\nprint(img)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"\"\"This Breast has {} conditions with an {:.2f} percent confidence.\n    \n    Note Benign is not cancers cell while malignant is cancer cell\n    \"\"\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:31:14.418375Z","iopub.execute_input":"2021-07-02T12:31:14.418931Z","iopub.status.idle":"2021-07-02T12:31:14.516631Z","shell.execute_reply.started":"2021-07-02T12:31:14.418884Z","shell.execute_reply":"2021-07-02T12:31:14.515805Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"<PIL.Image.Image image mode=RGB size=180x180 at 0x7FA8A3D7E090>\nThis Breast has Malignant conditions with an 99.98 percent confidence.\n    \n    Note Benign is not cancers cell while malignant is cancer cell\n    \n","output_type":"stream"}]},{"cell_type":"code","source":"img=plt.imread('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (1).png')\nplt.imshow(img)\nplt.title(class_names[labels[i]])\nplt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}